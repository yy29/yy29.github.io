---
layout: archive
permalink: /
title: "Profile"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi I'm Youyang. I am an experienced industrial researcher specializing in  Computer Vision, Natural Language Processing, and Machine Learning, with track record in patents, publications, and practical implementations.

Currently, I lead a research team at Kioxia Corporation, Japan, focusing on basic and applied studies in Computer Vision, Natural Language Processing, Machine Learning, and Memory Systems. My research interests lie in the intersection of memory, intelligence, and alignment in vision and language models.

I have co-authored over 30 patents and research articles, including publications in notable venues such as ECCV, ACCV and EMNLP. Additionally, I have served as a reviewer for venues including ACL Rolling Review, WACV, ACL and EMNLP. I have received outstanding reviewer recognition at EMNLP. I am also a Senior Member of IEEE. With over 14 years of industrial R&D experiences, I previously worked at Toshiba Corporation and hold a B.Eng from Universiti Malaya, Malaysia. The tools I help develop inspect and analyze millions of visual data daily in social infrastructure & semiconductor industries. I speak English, Japanese, Chinese and Malay.

[Google Scholar](https://scholar.google.com/citations?user=4BGLw_QAAAAJ) &nbsp;&nbsp; [LinkedIn](https://www.linkedin.com/in/youyang-ng-55a10ab9/) &nbsp;&nbsp; [Publications List](publications.md)

Selected Works
======
## Aligning Human-AI Perception in Vision Foundation Models
<div class="paper-box"><div class="paper-box-image"><img src="../images/coming_soon.png" alt="sym" width="100%"></div>
<div class="paper-box-text" markdown="1">

**Prompt-Guided Attention Head Selection for Focus-Oriented Image Retrieval**  
Yuji Nozawa, Yu-Chieh Lin, Kazumoto Nakamura, <ins>Youyang Ng</ins>  
*IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2025 ([paper](https://arxiv.org/abs/2504.01348))*
</div>
</div>

<div class="paper-box"><div class="paper-box-image"><img src="../images/2024_itae.png" alt="sym" width="100%"></div>
<div class="paper-box-text" markdown="1">

**Improving Image Clustering with Artifacts Attenuation via Inference-Time Attention Engineering**  
Kazumoto Nakamura, Yuji Nozawa, Yu-Chieh Lin, Kengo Nakata, <ins>Youyang Ng</ins>  
*Asian Conference on Computer Vision (ACCV), 2024 ([paper](https://openaccess.thecvf.com/content/ACCV2024/html/Nakamura_Improving_Image_Clustering_with_Artifacts_Attenuation_via_Inference-Time_Attention_Engineering_ACCV_2024_paper.html))*
</div>
</div>

<div class="paper-box"><div class="paper-box-image"><img src="../images/2024_feedback.png" alt="sym" width="100%"></div>
<div class="paper-box-text" markdown="1">

**Revisiting Relevance Feedback for CLIP-based Interactive Image Retrieval**  
Ryoya Nara, Yu-Chieh Lin, Yuji Nozawa, <ins>Youyang Ng</ins>, Goh Itoh, Osamu Torii, Yusuke Matsui  
*European Conference on Computer Vision (ECCV) Workshops, 2024 ([paper](https://arxiv.org/abs/2404.16398))*
</div>
</div>

## Rethinking AI Models with Separable, Explainable & Editable Knowledge
<div class="paper-box"><div class="paper-box-image"><img src="../images/2022_knn.png" alt="sym" width="100%"></div>
<div class="paper-box-text" markdown="1">

**Revisiting a kNN-based Image Classification System with High-capacity Storage**  
Kengo Nakata, <ins>Youyang Ng</ins>, Daisuke Miyashita, Asuka Maki, Yu-Chieh Lin, Jun Deguchi  
*European Conference on Computer Vision (ECCV), 2022, **Oral** ([paper](https://arxiv.org/abs/2204.01186), [press](https://www.kioxia.com/en-jp/about/news/2022/20221102-1.html), [blog](https://www.kioxia.com/en-jp/rd/technology/topics/topics-39.html))*
</div>
</div>

<div class="paper-box"><div class="paper-box-image"><img src="../images/2024_sparse.png" alt="sym" width="100%"></div>
<div class="paper-box-text" markdown="1">

**Rethinking Sparse Lexical Representations for Image Retrieval in the Age of Rising Multi-Modal Large Language Models**  
Kengo Nakata, Daisuke Miyashita, <ins>Youyang Ng</ins>, Yasuto Hoshi, Jun Deguchi  
*European Conference on Computer Vision (ECCV) Workshops, 2024 ([paper](https://arxiv.org/abs/2408.16296), [blog](https://www.kioxia.com/en-jp/rd/technology/topics/topics-76.html))*
</div>
</div>

## Development of Retrieval-Augmented & Retrieval-Centric Generation
<div class="paper-box"><div class="paper-box-image"><img src="../images/2023_ralle.png" alt="sym" width="100%"></div>
<div class="paper-box-text" markdown="1">

**RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models**  
Yasuto Hoshi, Daisuke Miyashita, <ins>Youyang Ng</ins>, Kento Tatsuno, Yasuhiro Morioka, Osamu Torii, Jun Deguchi  
*Conference on Empirical Methods in Natural Language Processing (EMNLP) System Demonstrations, 2023 ([paper](https://arxiv.org/abs/2308.10633), [code](https://github.com/yhoshi3/RaLLe), [blog](https://www.kioxia.com/en-jp/rd/technology/topics/topics-58.html))*
</div>
</div>

<div class="paper-box"><div class="paper-box-image"><center><img src="../images/2023_simplyretrieve.png" alt="sym" width="50%"></center></div>
<div class="paper-box-text" markdown="1">

**SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative AI Tool**  
<ins>Youyang Ng</ins>, Daisuke Miyashita, Yasuto Hoshi, Yasuhiro Morioka, Osamu Torii, Tomoya Kodama, Jun Deguchi  
*arXiv, 2023 ([paper](https://arxiv.org/abs/2308.03983), [code](https://github.com/RCGAI/SimplyRetrieve), [blog](https://www.kioxia.com/en-jp/rd/technology/topics/topics-58.html))*
</div>
</div>
